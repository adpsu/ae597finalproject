from pyspark.sql import SparkSession
from pyspark.sql.functions import input_file_name, regexp_extract, sum as _sum
import pandas as pd
import matplotlib.pyplot as plt

# Create a Spark session
spark = SparkSession.builder \
    .appName("Aggregate and Plot") \
    .getOrCreate()

# Define the base directory
base_directory = "/path/to/model_year=2050/"

# Load Parquet files from directories that match the pattern
df = spark.read.parquet(base_directory + "subsector=Personal_LDV+*/metric=*/")

# Add a column with the file path using input_file_name
df = df.withColumn("file_path", input_file_name())

# Extract 'vehicle_type' from the file path
df = df.withColumn("vehicle_type", regexp_extract("file_path", "subsector=Personal_LDV\+([^/]+)", 1))

# Extract 'charger_type' from the file path
df = df.withColumn("charger_type", regexp_extract("file_path", "metric=([^/]+)", 1))

# Assuming the DataFrame already has a column named 'value' and 'geography'
# Group by 'geography' and sum the 'value'
aggregated_df = df.groupBy("geography").agg(_sum("value").alias("total_value"))

# Convert to Pandas DataFrame
pandas_df = aggregated_df.toPandas()

# Plotting
plt.figure(figsize=(10, 6))
plt.boxplot(pandas_df['total_value'])
plt.title('Box Plot of Total Values by Geography')
plt.ylabel('Total Value')
plt.xlabel('Geography')
plt.xticks([1], pandas_df['geography'])  # Adjust depending on the number of unique geographies
plt.grid(True)
plt.show()

# Stop the Spark session
spark.stop()
